<!DOCTYPE html>
<html>

<head>
  <script defer src="https://cloud.umami.is/script.js" data-website-id="028ba410-097e-443c-a63b-7e6f79597d30"></script>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="VisualSphinx">
  <meta property="og:title" content="VisualSphinx" />
  <meta property="og:description" content="Large-Scale Synthetic Vision Logic Puzzles for RL" />
  <meta property="og:url" content="https://visualsphinx.github.io/" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="VisualSphinx">
  <meta name="twitter:description" content="Large-Scale Synthetic Vision Logic Puzzles for RL">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Large-Scale Synthetic Vision Logic Puzzles for RL">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>VisualSphinx</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">VisualSphinx: Large-Scale Synthetic Vision Logic Puzzles for RL
              for Coding</h1>
            <div class="is-size-8 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="" target="_blank">Yichen Feng</a><sup>♠</sup>,</span>
              <span class="author-block">
                <a href="https://zhangchenxu.com/" target="_blank">Zhangchen Xu</a><sup>♠</sup>,</span>
              <span class="author-block">
                <a href="https://fqjiang.work/" target="_blank">Fengqing Jiang</a><sup>♠</sup>,</span>
              <span class="author-block">
                <a href="https://yuetl9.github.io/" target="_blank">Yuetai Li</a><sup>♠</sup>,</span>
              <span class="author-block">
                <a href="https://sites.google.com/view/rbhaskar" target="_blank">Bhaskar Ramasubramanian</a><sup>♢</sup>,</span>
              <span class="author-block">
                <a href="https://luyaoniu.github.io/" target="_blank">Luyao Liu</a><sup>♠</sup>,</span>
              <span class="author-block">
                <a href="https://yuchenlin.xyz/" target="_blank">Bill Yuchen Lin</a><sup>♠</sup>,</span>
              <span class="author-block">
                <a href="https://people.ece.uw.edu/radha/" target="_blank">Radha Poovendran</a><sup>♠</sup>,</span>
              </span>
            </div>

            <div class="is-size-8 publication-authors">
              <span class="author-block"><sup>♠</sup>University of Washington, <sup>♢</sup>Western Washington University</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2503.02951" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- HuggingFace Organization link -->
                <span class="link-block">
                  <a href="https://huggingface.co/KodCode" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      🤗
                    </span>
                    <span>HF Organization</span>
                  </a>
                </span>

                <!-- HuggingFace Dataset link -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/KodCode/KodCode-V1" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-database"></i>
                    </span>
                    <span>KodCode-V1 (RL)</span>
                  </a>
                </span>

                <!-- HuggingFace Dataset link -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/KodCode/KodCode-V1-SFT-R1" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-database"></i>
                    </span>
                    <span>KodCode-V1-SFT-R1</span>
                  </a>
                </span>


                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/KodCode-AI/kodcode" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Codebase</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We introduce <b>KodCode</b>, a <b>synthetic dataset</b> that addresses the persistent challenge of
              acquiring <b>high-quality, verifiable training data</b> across <b>diverse difficulties and domains</b> for
              training Large Language Models for coding. Existing code-focused resources typically fail to ensure either
              the breadth of coverage (e.g., spanning simple coding tasks to advanced algorithmic problems) or
              verifiable correctness (e.g., unit tests). In contrast, KodCode comprises <b>question-solution-test
                triplets</b> that are systematically validated via a self-verification procedure. Our pipeline begins by
              synthesizing a broad range of coding questions, then generates solutions and test cases with additional
              attempts allocated to challenging problems. Finally, post-training data synthesis is done by rewriting
              questions into diverse formats and generating responses under a test-based reject sampling procedure from
              a reasoning model (DeepSeek R1). This pipeline yields a large-scale, robust and diverse coding dataset.
              KodCode is suitable for supervised fine-tuning and the paired unit tests also provide great potential for
              RL tuning. Fine-tuning experiments on coding benchmarks (HumanEval(+), MBPP(+), BigCodeBench, and
              LiveCodeBench) demonstrate that KodCode-tuned models achieve state-of-the-art performance, surpassing
              models like Qwen2.5-Coder-32B-Instruct and DeepSeek-R1-Distill-Llama-70B.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Optional section title -->
      <div class="has-text-centered">
        <h2 class="title is-3">KodCode Pipeline</h2>
      </div>
      <br>
      <!-- Figure on top -->

      <figure class="image" style="width: 95%; margin: 0 auto;">
        <img src="static/images/kodcode-pipeline.jpg" alt="" />
      </figure>
      <br>
      <p class="has-text-left">
        This figure demonstrates the pipeline for generating KodCode-V1. Our approach follows a three-step pipeline:
        <i>Coding Question Synthesis</i>, <i>Solution & Test Generation</i>, and <i>Post-training Data Synthesis</i>.
        The final KodCode-V1 dataset contains <b>447K verified question-solution-test triplets</b>. The distribution of
        each subset is demonstrated on the right.
      </p>
    </div>
  </section>

  <section class="section"></section>
  <div class="container is-max-desktop">
    <!-- Optional section title -->
    <div class="has-text-centered">
      <h2 class="title is-3">✨ KodCode is Diverse! ✨</h2>
    </div>
    <br>
    <!-- Figure on top -->

    <figure class="image" style="width: 95%; margin: 0 auto;">
      <img src="static/images/diversity.jpg" alt="" />
    </figure>
    <br>
    <p class="has-text-left">
      This figure demonstrates the diversity of KodCode-V1. We present statistics on questions, solutions, and number of
      tests, as well as the distribution of each subset compared with baselines.
    </p>
  </div>
  </section>

  <section class="section"></section>
  <div class="container is-max-desktop">
    <!-- Optional section title -->
    <div class="has-text-centered">
      <h2 class="title is-3">✨ KodCode is Challenging! ✨</h2>
    </div>
    <br>
    <!-- Figure on top -->

    <figure class="image" style="width: 95%; margin: 0 auto;">
      <img src="static/images/challenging.jpg" alt="" />
    </figure>
    <br>
    <p class="has-text-left">
      This figure shows the difficulty of KodCode-V1. Importantly, we found that allocating more attempts to challenging
      problems is effective in improving pass rates for these problems.
    </p>
  </div>
  </section>

  <section class="section"></section>
  <div class="container is-max-desktop">
    <!-- Optional section title -->
    <div class="has-text-centered">
      <h2 class="title is-3">✨ Performance on Coding Benchmarks ✨</h2>
    </div>
    <br>
    <!-- Figure on top -->

    <figure class="image" style="width: 95%; margin: 0 auto;">
      <img src="static/images/performance comparison.png" alt="" />
    </figure>
    <br>
    <p class="has-text-left">
      This figure shows the performance of KodCode-SFT on coding benchmarks. We compare KodCode with SOTA non-reasoning
      and reasoning models on HumanEval(+), MBPP(+), BigCodeBench, and LiveCodeBench.
    </p>
    <br>
  </div>
  </section>

  <!-- Image carousel -->
  <!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
  <!-- <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
  <!-- <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
  <!-- <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
  <!-- <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Fourth image description.
        </h2>
    </div>
  </div>
</div>
</div>
</section> -->
  <!-- End image carousel -->




  <!-- Kodkod introduction and video -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">🐱 Meet Kodkod: Nature's Stealthy Programmer! 🐾</h2>
        <div class="columns is-centered">
          <div class="column is-four-fifths">
            <div class="content has-text-justified">
              <p>
                Kodkod (Leopardus guigna) is a wild cat species native to the Americas, known for its adaptability and
                resilience in various environments. Just as the Kodkod navigates through diverse habitats, from dense
                forests to open areas, KodCode is designed to handle various programming challenges with agility and
                precision.
              </p>
            </div>
            <div class="publication-video">
              <!-- Youtube embed code here -->
              <iframe src="https://www.youtube.com/embed/BFA6hxfnVjM" frameborder="0" allow="autoplay; encrypted-media"
                allowfullscreen></iframe>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End Kodkod introduction and video -->


  <!-- 
Video carousel
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            Your video file here
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            Your video file here
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            Your video file here
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
End video carousel 
-->


  <!-- 
Paper poster
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
End paper poster 
-->

  <!-- 
Teaser video
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        Your video here
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Why we name it KodCode?
      </h2>
    </div>
  </div>
</section>
End teaser video 
-->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{xu2025kodcode,
        title={KodCode: A Diverse, Challenging, and Verifiable Synthetic Dataset for Coding}, 
        author={Zhangchen Xu and Yang Liu and Yueqin Yin and Mingyuan Zhou and Radha Poovendran},
        year={2025},
        eprint={2503.02951},
        archivePrefix={arXiv},
        primaryClass={cs.LG},
        url={https://arxiv.org/abs/2503.02951}, 
  }</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>